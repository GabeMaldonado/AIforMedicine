{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIforMed_C3_W1_Lab2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPtsYTx39jrua9KHMCTmCCZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GabeMaldonado/AIforMedicine/blob/master/AIforMed_C3_W1_Lab2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2M9XpVRIoZ8",
        "colab_type": "text"
      },
      "source": [
        "$\\mathfrak{Gabriel \\ Maldonado}$\n",
        "\n",
        "# AI for Medicine Course III\n",
        "## Week 1 Lab 1 \n",
        "## Model Training/Tuning Basics with Sklearn\n",
        "\n",
        "In this notebook we're going to be exploring the `sklearn` library, including an overview of its underlying data types and methods for tweaking a model's hyperparameters using some dummy data.\n",
        "\n",
        "### Packages\n",
        "\n",
        "We will be using the following packages \n",
        "\n",
        "- `pandas` -- to manipulate the data\n",
        "- `numpy`  -- for mathematical and scientific operations\n",
        "- `sklearn`  -- for machine learning and statistical modeling\n",
        "- `itertools` helps with hyperparameter (grid) searching"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-hOJH4qJaWs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "18aa9a72-174c-4a20-d470-a78f6916bec5"
      },
      "source": [
        "# Import Packages\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "# Set the random seed for consistent output\n",
        "np.random.seed(18)\n",
        "\n",
        "# Read in the data\n",
        "data = pd.read_csv(\"/content/dummy_data.csv\", index_col=0)\n",
        "data.head()\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sex</th>\n",
              "      <th>age</th>\n",
              "      <th>obstruct</th>\n",
              "      <th>outcome</th>\n",
              "      <th>TRTMT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>57</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>68</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>66</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>69</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sex  age  obstruct  outcome  TRTMT\n",
              "1    0   57         0        1   True\n",
              "2    1   68         0        0  False\n",
              "3    0   72         0        0   True\n",
              "4    0   66         1        1   True\n",
              "5    1   69         0        1  False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlW2JC81KdIR",
        "colab_type": "text"
      },
      "source": [
        "### Train/Test Split\n",
        "\n",
        "In this step we will split the data into train and test sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAfkEAH2KYAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ac12919c-5d2b-4c45-81f2-a119c79bbc8d"
      },
      "source": [
        "# Import module to split data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Get the label\n",
        "y = data.outcome\n",
        "\n",
        "# Get the features\n",
        "X = data.drop('outcome', axis=1)\n",
        "\n",
        "# Get training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30)\n",
        "\n",
        "print(f\"Number of observations for training: {y_train.size}\")\n",
        "print(f\"Number of observations for testing: {y_test.size}\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of observations for training: 35\n",
            "Number of observations for testing: 15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxfGOTodNTD1",
        "colab_type": "text"
      },
      "source": [
        "### Model Fit and Prediction\n",
        "\n",
        "Let's fit a logistic regression to the training data. `Sklearn` allows you to provide arguments that override the defaults. \n",
        "\n",
        "The default solver is `lbfgs`.  \n",
        "- Lbfgs stands for ['Limited Memory BFGS'](https://en.wikipedia.org/wiki/Limited-memory_BFGS), and is an efficient and popular method for fitting models.\n",
        "- The solver is set explicitly here for learning purposes; if you do not set the solver parameter explicitly, the [LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) function will use its default solver, which is lbfgs as well."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uof7CpnNFie",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "98f3dff6-b23d-4331-9ae3-ccf147756d62"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Create an instance of a model\n",
        "lr = LogisticRegression(solver = 'lbfgs')\n",
        "\n",
        "# Fit the model\n",
        "lr.fit(X_train, y_train)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8VF3u-UKOKu6",
        "colab_type": "text"
      },
      "source": [
        "When it fits the training data, `sklearn` also prints out the model's hyperparameters.  \n",
        "- Here, these are the default hyperparameters for `sklearn's` logistic regression classifier.\n",
        "- Another way to check these parameters is the `get_params()` method of the classifier.\n",
        "\n",
        "You should spend some time checking out the [documentation](https://scikit-learn.org/stable/supervised_learning.html#supervised-learning) to get a deeper understanding of what's going on. One important thing to note is that each classifier has different hyperparameters. \n",
        "\n",
        "### Prediction\n",
        "To predict with the classifier, use the `predict()` method. \n",
        "- This returns a `numpy` array containing the predicted class for each observation in the test set, as you can see by running the next cell:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL8rm2yvOXpu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ed1e1fb2-9d74-436a-f9e1-1433b8d062b5"
      },
      "source": [
        "# Use the trained model to predict labels from the features of the test set\n",
        "predictions = lr.predict(X_test)\n",
        "\n",
        "# View the prediction type, shape, and print out a sample prediction\n",
        "print(f\"predictions is of type: {type(predictions)}\")\n",
        "print(f\"predictions has shape: {predictions.shape}\")\n",
        "print(f\"predicted class for 10th element in test set: {predictions[9]}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "predictions is of type: <class 'numpy.ndarray'>\n",
            "predictions has shape: (15,)\n",
            "predicted class for 10th element in test set: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ihz6QkBhOpun",
        "colab_type": "text"
      },
      "source": [
        "### Prediction probability\n",
        "\n",
        "When a model predicts that a label is 1 rather than 0, it may help you to know if the model was predicting 1 with a 51% probability or 90% probability; in other words, how confident is that prediction?\n",
        "\n",
        "You can get the model's probability of predicting each of the class. \n",
        "- To do this, use the `predict_proba()` method. \n",
        "- The resulting array will have a shape that matches the number of classes for the target variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXxE-FdyOgpm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "81a54c12-a9c9-446b-b064-02fbef7fd010"
      },
      "source": [
        "prediction_probs = lr.predict_proba(X_test)\n",
        "print(f\"prediction_probs is of type: {type(prediction_probs)}\")\n",
        "print(f\"prediction_probs has shape: {prediction_probs.shape}\")\n",
        "print(f\"probabilities for first element in test set: {prediction_probs[9]}\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prediction_probs is of type: <class 'numpy.ndarray'>\n",
            "prediction_probs has shape: (15, 2)\n",
            "probabilities for first element in test set: [0.52049488 0.47950512]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eGF24bVOytK",
        "colab_type": "text"
      },
      "source": [
        "There are 13 patients in the test set.  Each patient's label could be either 0 or 1, so the prediction probability has 13 rows and 2 columns.  To know which column refers to label 0 and which refers to label 1, you can check the `.classes_` attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiScT2X1OtlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d58a4dc-017c-4a2f-cbf5-1fc14a4cc7b3"
      },
      "source": [
        "lr.classes_"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l9AKE5oxPMMG",
        "colab_type": "text"
      },
      "source": [
        "Since the order of the `classes_` array is 0, then 1, column 0 of the prediction probabilities has label 0, and column 1 has label 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ibc_zfGRO6DI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "outputId": "72f1f9ce-2882-4680-f7c7-a1fcea397be8"
      },
      "source": [
        "# Print the first 5 elements of the dataset\n",
        "\n",
        "for i in range(5):\n",
        "    print(f\"Element number: {i}\")\n",
        "    print(f\"Predicted class: {predictions[i]}\")\n",
        "    print(f\"Probability of predicting class 0: {prediction_probs[i][0]}\")\n",
        "    print(f\"Probability of predicting class 1: {prediction_probs[i][1]}\\n\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Element number: 0\n",
            "Predicted class: 1\n",
            "Probability of predicting class 0: 0.4163960798121926\n",
            "Probability of predicting class 1: 0.5836039201878074\n",
            "\n",
            "Element number: 1\n",
            "Predicted class: 1\n",
            "Probability of predicting class 0: 0.487859105386813\n",
            "Probability of predicting class 1: 0.512140894613187\n",
            "\n",
            "Element number: 2\n",
            "Predicted class: 1\n",
            "Probability of predicting class 0: 0.47448109788199044\n",
            "Probability of predicting class 1: 0.5255189021180096\n",
            "\n",
            "Element number: 3\n",
            "Predicted class: 0\n",
            "Probability of predicting class 0: 0.8518210817782923\n",
            "Probability of predicting class 1: 0.14817891822170776\n",
            "\n",
            "Element number: 4\n",
            "Predicted class: 0\n",
            "Probability of predicting class 0: 0.8287608087287452\n",
            "Probability of predicting class 1: 0.17123919127125475\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mt5nr_7RPcDB",
        "colab_type": "text"
      },
      "source": [
        "We can see here that the predicted class matches the class with a higher probability of being predicted. Since you're dealing with `numpy` arrays, you can simply slice them and get specific information, such as the probability of predicting class 1 for all elements in the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtMtKBoZPTs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e86a3a2e-6c66-4b4b-87ab-6979fc3546ef"
      },
      "source": [
        "# Retrieve prediction probabilities for label 1, for all patients\n",
        "prediction_probs[:, 1]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.58360392, 0.51214089, 0.5255189 , 0.14817892, 0.17123919,\n",
              "       0.29148012, 0.51712649, 0.33070589, 0.40522705, 0.47950512,\n",
              "       0.17606497, 0.5081346 , 0.29847409, 0.19057603, 0.38912412])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhCQIl8TPuBr",
        "colab_type": "text"
      },
      "source": [
        "### Tuning the Model\n",
        "\n",
        "Most of the time, the predictive power of a classifier can be increased if a good set of hyperparameters is defined. This is known as model tuning. \n",
        "\n",
        "For this process, you'll need a classifier, an appropriate evaluation metric, and a set of parameters to test. Since this is a dummy example, you'll use the default metric for the logistic regression classifier: the **mean accuracy**.\n",
        "\n",
        "### Mean Accuracy\n",
        "Mean Accuracy is the number of correct predictions divided by total predictions. This can be computed with the `score()` method. \n",
        "\n",
        "Let's begin by checking the performance of the out-of-the-box logit classifier:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b3XBKtKlPrJD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7a26e689-46a7-4145-af45-a7ac702367b8"
      },
      "source": [
        "lr.score(X_test, y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6666666666666666"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjF1JPaQQB9F",
        "colab_type": "text"
      },
      "source": [
        "Let's say we want to tweak this model's default parameters. We can pass a dictionary containing the values we specify to the classifier when we instantiate it. Notice that these must be passed as keyword arguments, or `kwargs`, which are created by using the ** prefix:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLreJE3DP9QD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "9f3fb729-a31d-4158-f31e-d4465a8d6acd"
      },
      "source": [
        "# Choose hyperparameters and place them as key-value pairs in a dictionary\n",
        "params = {\n",
        "    'solver': 'liblinear',\n",
        "    'fit_intercept': False,\n",
        "    'penalty': 'l1',\n",
        "    'max_iter': 500\n",
        "}\n",
        "\n",
        "# Pass in the dictionary as keyword arguments to the model\n",
        "lr_tweaked = LogisticRegression(**params)\n",
        "\n",
        "# Train the model\n",
        "lr_tweaked.fit(X_train, y_train)\n",
        "\n",
        "# View hyper-parameters\n",
        "print(f\"Tweaked hyperparameters: {lr_tweaked.get_params()}\\n\")\n",
        "\n",
        "# Evaluate the model with the mean accuracy\n",
        "print(f\"Mean Accuracy: {lr_tweaked.score(X_test, y_test)}\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tweaked hyperparameters: {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': False, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 500, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l1', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
            "\n",
            "Mean Accuracy: 0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptnkBVLvQoFW",
        "colab_type": "text"
      },
      "source": [
        "The model with the tweaked parameters is about the same as the original! However, there might still be some combination of parameters that can increase the predictive power of the logit classifier. \n",
        "\n",
        "### Trying  Different Hyperparameters\n",
        "Testing this can be daunting considering all the possible parameter combinations. Let's try something \n",
        "\n",
        "To get started, we'll apply `itertools.product()` to create all the combinations of parameters. \n",
        "- Notice that the iterable (in this case a list of the lists of parameters) must be passed as *args to the `product()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aP6nuMycQZNJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6390efbb-49b1-4763-eea6-3d13ca7f2002"
      },
      "source": [
        "# Choose hyperparameters and place in a dictionary\n",
        "hyperparams = {\n",
        "    'solver': [\"liblinear\"],\n",
        "    'fit_intercept': [True, False],\n",
        "    'penalty': [\"l1\", \"l2\"],\n",
        "    'class_weight': [None, \"balanced\"]\n",
        "}\n",
        "# Get the values of hyperparams and convert them to a list of lists\n",
        "hp_values = list(hyperparams.values())\n",
        "hp_values"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['liblinear'], [True, False], ['l1', 'l2'], [None, 'balanced']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z4_xmqi_Rdk0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e843eda-211d-41d5-9ebb-dee1b7ad8f93"
      },
      "source": [
        "hp_keys = list(hyperparams.keys())\n",
        "hp_keys"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['solver', 'fit_intercept', 'penalty', 'class_weight']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7uzdo8HwRHWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "66c716d0-5f67-4280-d39f-2b9f418228d2"
      },
      "source": [
        "# Get every combination of the hyperparameters\n",
        "for hp in itertools.product(*hp_values):\n",
        "    print(hp)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('liblinear', True, 'l1', None)\n",
            "('liblinear', True, 'l1', 'balanced')\n",
            "('liblinear', True, 'l2', None)\n",
            "('liblinear', True, 'l2', 'balanced')\n",
            "('liblinear', False, 'l1', None)\n",
            "('liblinear', False, 'l1', 'balanced')\n",
            "('liblinear', False, 'l2', None)\n",
            "('liblinear', False, 'l2', 'balanced')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uztXbJRGRqaT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "1a7f9ec7-c679-44da-b28e-2b6cd37e0d80"
      },
      "source": [
        "# Loop through the combinations of hyperparams\n",
        "for hp in itertools.product(*hp_values):\n",
        "\n",
        "    # Create the model with the hyperparams\n",
        "    estimator = LogisticRegression(solver=hp[0],\n",
        "                                   fit_intercept=hp[1],\n",
        "                                   penalty=hp[2],\n",
        "                                   class_weight=hp[3])\n",
        "    # Fit the model\n",
        "    estimator.fit(X_train, y_train)\n",
        "    print(f\"Parameters used: {hp}\")\n",
        "    print(f\"Mean accuracy of the model: {estimator.score(X_test, y_test)}\\n\")"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Parameters used: ('liblinear', True, 'l1', None)\n",
            "Mean accuracy of the model: 0.6\n",
            "\n",
            "Parameters used: ('liblinear', True, 'l1', 'balanced')\n",
            "Mean accuracy of the model: 0.5333333333333333\n",
            "\n",
            "Parameters used: ('liblinear', True, 'l2', None)\n",
            "Mean accuracy of the model: 0.4666666666666667\n",
            "\n",
            "Parameters used: ('liblinear', True, 'l2', 'balanced')\n",
            "Mean accuracy of the model: 0.5333333333333333\n",
            "\n",
            "Parameters used: ('liblinear', False, 'l1', None)\n",
            "Mean accuracy of the model: 0.6\n",
            "\n",
            "Parameters used: ('liblinear', False, 'l1', 'balanced')\n",
            "Mean accuracy of the model: 0.5333333333333333\n",
            "\n",
            "Parameters used: ('liblinear', False, 'l2', None)\n",
            "Mean accuracy of the model: 0.4\n",
            "\n",
            "Parameters used: ('liblinear', False, 'l2', 'balanced')\n",
            "Mean accuracy of the model: 0.5333333333333333\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OH_yNMDSLC1",
        "colab_type": "text"
      },
      "source": [
        "### That was Grid Search!\n",
        "\n"
      ]
    }
  ]
}